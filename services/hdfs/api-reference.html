<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">







<head>
<title>HDFS: API Reference</title>
<link rel="stylesheet" type="text/css" media="all" href="../../style/gh-basic.css" />
<link rel="shortcut icon" type="image/png" href="https://mesosphere.com/favicon.ico"/>
<!-- The Dropdown library is written by Stephen Morley, licensed CC0 1.0 Universal (Public Domain Dedication)-->
<link rel="stylesheet" type="text/css" media="all" href="../../style/Dropdown.css" />
<script src="../../style/Dropdown.js"></script>
<style type="text/css">
/* set the background color of menu items */
.dropdown, .dropdown ul { background: #555555; clear: both; }
/* set the background color of active items */
.dropdown li:hover > a, .dropdown li:hover > span, .dropdown li.dropdownOpen > a, .dropdown li.dropdownOpen > span { background: #af87e0; }
/* pad items, set their text color, and fade their background color */
.dropdown a, .dropdown span { padding: 0.25em 0.5em; color: white; transition: background 0.2s; }
/* show '+' on expandable items */
.dropdown span:after { content: " +"; }

/* toc style: remove extra margin between elements */
#markdown-toc ul { margin: 0; }
</style>
</head>

<body>
<div id="wrapper">

<a href="../..">
<img style="float: left; margin-bottom: 2em" src="https://mesosphere.com/wp-content/themes/mesosphere/library/images/assets/dcos-sdk-logo.png" width="250" alt="DC/OS Software Development Kit" />
</a>
<img style="float: right" src="https://img.shields.io/badge/Status-Alpha-BF97F0.svg?style=flat-square" alt="Status: Alpha" />

<ul class="dropdown" style="clear: both">
  <li>
    <a href="../..">Home</a>
  </li>
  <li>
    <span>Documentation</span>
    <ul>
      
      
      
      
      <li><a href="../../developer-guide.html">SDK Developer Guide</a></li>
      
      
      
      <li><a href="../../operations-guide.html">SDK Operations Guide</a></li>
      
      
      
      <li><a href="../../faq.html">Frequently Asked Questions</a></li>
      
      
      
      <li><a href="../../glossary.html">Glossary</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </li>
  <li>
    <span>Tutorials</span>
    <ul>
      
      
      
      <li><a href="../../tutorials/secrets-tutorial.html">Secrets Tutorial</a></li>
      
      <li><a href="../../tutorials/kafka-tutorial.html">Kafka Tutorial</a></li>
      
    </ul>
  </li>
  <li>
    <span>Reference</span>
    <ul>
      
      
      
      <li><a href="../../reference/yaml-reference.html">YAML Reference</a></li>
      
      <li><a href="../../reference/api">Javadoc Reference</a></li>
      <li><a href="../../reference/swagger-api">REST APIs</a></li>
    </ul>
  </li>
  <li>
    <span>Services</span>
    <ul>
      
      
      
      
      <li>
        
        <span>Elastic</span>
        
        <ul>
          
          
          <li><a href="../../services/elastic/install.html">Install and Customize</a></li>
          
          <li><a href="../../services/elastic/elastic-x-pack.html">X-Pack</a></li>
          
          <li><a href="../../services/elastic/custom-elasticsearch-yaml.html">Custom Elasticsearch YAML</a></li>
          
          <li><a href="../../services/elastic/uninstall.html">Uninstall</a></li>
          
          <li><a href="../../services/elastic/quick-start.html">Quick Start</a></li>
          
          <li><a href="../../services/elastic/connecting-clients.html">Connecting Clients</a></li>
          
          <li><a href="../../services/elastic/managing.html">Managing</a></li>
          
          <li><a href="../../services/elastic/api-reference.html">API Reference</a></li>
          
          <li><a href="../../services/elastic/disaster-recovery.html">Disaster Recovery</a></li>
          
          <li><a href="../../services/elastic/troubleshooting.html">Troubleshooting</a></li>
          
          <li><a href="../../services/elastic/limitations.html">Limitations</a></li>
          
          <li><a href="../../services/elastic/supported-versions.html">Supported Versions</a></li>
          
          <li><a href="../../services/elastic/release-notes.html">Release Notes</a></li>
          
          <li><a href="../../services/elastic/upgrade.html">Upgrade</a></li>
          
        </ul>
      </li>
      
      <li>
        
        <span>HDFS</span>
        
        <ul>
          
          
          <li><a href="../../services/hdfs/install.html">Install and Customize</a></li>
          
          <li><a href="../../services/hdfs/kerberos.html">Kerberos</a></li>
          
          <li><a href="../../services/hdfs/uninstall.html">Uninstall</a></li>
          
          <li><a href="../../services/hdfs/quick-start.html">Quickstart</a></li>
          
          <li><a href="../../services/hdfs/connecting-clients.html">Connecting Clients</a></li>
          
          <li><a href="../../services/hdfs/managing.html">Managing</a></li>
          
          <li><a href="../../services/hdfs/api-reference.html">API Reference</a></li>
          
          <li><a href="../../services/hdfs/troubleshooting.html">Troubleshooting</a></li>
          
          <li><a href="../../services/hdfs/limitations.html">Limitations</a></li>
          
          <li><a href="../../services/hdfs/supported-versions.html">Supported Versions</a></li>
          
          <li><a href="../../services/hdfs/release-notes.html">Release Notes</a></li>
          
          <li><a href="../../services/hdfs/upgrade.html">Upgrade</a></li>
          
        </ul>
      </li>
      
      <li>
        
        <span>Kafka</span>
        
        <ul>
          
          
          <li><a href="../../services/kafka/install.html">Install and Customize</a></li>
          
          <li><a href="../../services/kafka/kerberos.html">Kerberos</a></li>
          
          <li><a href="../../services/kafka/ssl-auth.html">SSL Auth</a></li>
          
          <li><a href="../../services/kafka/uninstall.html">Uninstall</a></li>
          
          <li><a href="../../services/kafka/quick-start.html">Quick Start</a></li>
          
          <li><a href="../../services/kafka/connecting-clients.html">Connecting Clients</a></li>
          
          <li><a href="../../services/kafka/api-reference.html">API Reference</a></li>
          
          <li><a href="../../services/kafka/troubleshooting.html">Troubleshooting</a></li>
          
          <li><a href="../../services/kafka/limitations.html">Limitations</a></li>
          
          <li><a href="../../services/kafka/supported-versions.html">Supported Versions</a></li>
          
          <li><a href="../../services/kafka/release-notes.html">Release Notes</a></li>
          
          <li><a href="../../services/kafka/upgrade.html">Upgrade</a></li>
          
        </ul>
      </li>
      
    </ul>
  </li>
  <li><a href="https://github.com/mesosphere/dcos-commons/blob/master/CONTRIBUTING.md">Contributing</a></li>
  <li><a href="http://chat.dcos.io" target="_blank">Slack</a></li>
</ul>
<h1>HDFS: API Reference</h1>
<div id="content">
<!--  disable mustache templating in this file: retain templated examples as-is -->

<p>The DC/OS HDFS Service implements a REST API that may be accessed from outside the cluster. The <dcos_url> parameter referenced below indicates the base URL of the DC/OS cluster on which the HDFS Service is deployed.</dcos_url></p>

<p><a name="#rest-auth"></a></p>
<h1 id="rest-api-authentication">REST API Authentication</h1>
<p>REST API requests must be authenticated. This authentication is only applicable for interacting with the HDFS REST API directly. You do not need the token to access the HDFS nodes themselves.</p>

<p>If you are using Enterprise DC/OS, follow these instructions to <a href="https://docs.mesosphere.com/1.9/security/service-auth/custom-service-auth/">create a service account and an authentication token</a>. You can then configure your service to automatically refresh the authentication token when it expires. To get started more quickly, you can also <a href="https://docs.mesosphere.com/1.9/security/iam-api/">get the authentication token without a service account</a>, but you will need to manually refresh the token.</p>

<p>If you are using open source DC/OS, follow these instructions to <a href="https://dcos.io/docs/1.9/security/iam-api/">pass your HTTP API token to the DC/OS endpoint</a>.</p>

<p>Once you have the authentication token, you can store it in an environment variable and reference it in your REST API calls:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span><span class="nb">export </span><span class="nv">auth_token</span><span class="o">=</span>uSeR_t0k3n
</code></pre>
</div>

<p>The <code class="highlighter-rouge">curl</code> examples in this document assume that an auth token has been stored in an environment variable named <code class="highlighter-rouge">auth_token</code>.</p>

<p>If you are using Enterprise DC/OS, the security mode of your installation may also require the <code class="highlighter-rouge">--ca-cert</code> flag when making REST calls. Refer to <a href="https://docs.mesosphere.com/1.9/networking/tls-ssl/#get-dcos-cert">Obtaining and passing the DC/OS certificate in cURL requests</a> for information on how to use the <code class="highlighter-rouge">--cacert</code> flag. <a href="https://docs.mesosphere.com/1.9/networking/tls-ssl/">If your security mode is <code class="highlighter-rouge">disabled</code></a>, do not use the <code class="highlighter-rouge">--ca-cert</code> flag.</p>

<h1 id="plan-api">Plan API</h1>
<p>The Plan API provides endpoints for monitoring and controlling service installation and configuration updates.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/plans/deploy
</code></pre>
</div>
<h2 id="pause-installation">Pause Installation</h2>

<p>The installation will pause after completing installation of the current node and wait for user input.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl -X POST -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/plans/deploy/interrupt
</code></pre>
</div>

<h2 id="resume-installation">Resume Installation</h2>

<p>The REST API request below will resume installation at the next pending node.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl -X PUT &lt;dcos_surl&gt;/service/hdfs/v1/plans/deploy/continue
</code></pre>
</div>

<h1 id="connection-api">Connection API</h1>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> dcos_url/service/hdfs/v1/endpoints/hdfs-site.xml
</code></pre>
</div>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/endpoints/core-site.xml
</code></pre>
</div>

<p>You will see a response similar to the following:</p>

<div class="language-xml highlighter-rouge"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;</span>
<span class="cp">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.nameservice.id<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>hdfs<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.nameservices<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>hdfs<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.ha.namenodes.hdfs<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>name-0-node,name-1-node<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

    <span class="c">&lt;!-- namenode --&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.shared.edits.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>qjournal://journal-0-node.hdfs.autoip.dcos.thisdcos.directory:8485;journal-1-node.hdfs.autoip.dcos.thisdcos.directory:8485;journal-2-node.hdfs.autoip.dcos.thisdcos.directory:8485/hdfs<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.name.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>/name-data<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.safemode.threshold-pct<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.9<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.heartbeat.recheck-interval<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>60000<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.handler.count<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>20<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.invalidate.work.pct.per.iteration<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.95<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.replication.work.multiplier.per.iteration<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>4<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.datanode.registration.ip-hostname-check<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>false<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>


    <span class="c">&lt;!-- name-0-node --&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.rpc-address.hdfs.name-0-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>name-0-node.hdfs.autoip.dcos.thisdcos.directory:9001<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.rpc-bind-host.hdfs.name-0-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.http-address.hdfs.name-0-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>name-0-node.hdfs.autoip.dcos.thisdcos.directory:9002<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.http-bind-host.hdfs.name-0-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>


    <span class="c">&lt;!-- name-1-node --&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.rpc-address.hdfs.name-1-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>name-1-node.hdfs.autoip.dcos.thisdcos.directory:9001<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.rpc-bind-host.hdfs.name-1-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.http-address.hdfs.name-1-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>name-1-node.hdfs.autoip.dcos.thisdcos.directory:9002<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.http-bind-host.hdfs.name-1-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

    <span class="c">&lt;!-- journalnode --&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.journalnode.rpc-address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0:8485<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.journalnode.http-address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0:8480<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.journalnode.edits.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>/journal-data<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

    <span class="c">&lt;!-- datanode --&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0:9003<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.http.address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0:9004<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.ipc.address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0:9005<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.data.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>/data-data<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.balance.bandwidthPerSec<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>41943040<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.handler.count<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>10<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

    <span class="c">&lt;!-- HA --&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>ha.zookeeper.quorum<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>master.mesos:2181<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.ha.fencing.methods<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>shell(/bin/true)<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.ha.automatic-failover.enabled<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>


    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.image.compress<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.image.compression.codec<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>org.apache.hadoop.io.compress.SnappyCodec<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.client.read.shortcircuit<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.client.read.shortcircuit.streams.cache.size<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>1000<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.client.read.shortcircuit.streams.cache.size.expiry.ms<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>1000<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.client.failover.proxy.provider.hdfs<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.domain.socket.path<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>dn_socket<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.permissions.enabled<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>false<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;/configuration&gt;</span>
</code></pre>
</div>

<div class="language-xml highlighter-rouge"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;</span>
<span class="cp">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.default.name<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>hdfs://hdfs<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.proxyuser.hue.hosts<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>*<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.proxyuser.hue.groups<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>*<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.proxyuser.root.hosts<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>*<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.proxyuser.root.groups<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>*<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.proxyuser.httpfs.groups<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>*<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.proxyuser.httpfs.hosts<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>*<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>ha.zookeeper.parent-znode<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>/dcos-service-hdfs/hadoop-ha<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;/configuration&gt;</span>
</code></pre>
</div>
<p>The contents of the responses represent valid hdfs-site.xml and core-site.xml that can be used by clients to connect to the service.</p>

<h1 id="nodes-api">Nodes API</h1>

<p>The pod API provides endpoints for retrieving information about nodes, restarting them, and replacing them.</p>

<h2 id="list-nodes">List Nodes</h2>

<p>A list of available node ids can be retrieved by sending a GET request to <code class="highlighter-rouge">/v1/pod</code>:</p>

<p>CLI Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>dcos beta-hdfs --name<span class="o">=</span>hdfs pod list
</code></pre>
</div>

<p>HTTP Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl  -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/pod
<span class="o">[</span>
    <span class="s2">"data-0"</span>,
    <span class="s2">"data-1"</span>,
    <span class="s2">"data-2"</span>,
    <span class="s2">"journal-0"</span>,
    <span class="s2">"journal-1"</span>,
    <span class="s2">"journal-2"</span>,
    <span class="s2">"name-0"</span>,
    <span class="s2">"name-1"</span>,
    <span class="s2">"zkfc-0"</span>,
    <span class="s2">"zkfc-1"</span>
<span class="o">]</span>
</code></pre>
</div>

<h2 id="node-info">Node Info</h2>

<p>You can retrieve node information by sending a GET request to <code class="highlighter-rouge">/v1/pod/&lt;node-id&gt;/info</code>:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl  -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/pod/&lt;node-id&gt;/info
</code></pre>
</div>

<p>CLI Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>dcos beta-hdfs pod info --name<span class="o">=</span>hdfs journal-0
</code></pre>
</div>

<p>HTTP Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl  -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/pod/journal-0/info
<span class="o">[{</span>
	info: <span class="o">{</span>
		name: <span class="s2">"journal-0-node"</span>,
		taskId: <span class="o">{</span>
			value: <span class="s2">"journal-0-node__b31a70f4-73c5-4065-990c-76c0c704b8e4"</span>
		<span class="o">}</span>,
		slaveId: <span class="o">{</span>
			value: <span class="s2">"0060634a-aa2b-4fcc-afa6-5569716b533a-S5"</span>
		<span class="o">}</span>,
		resources: <span class="o">[{</span>
			name: <span class="s2">"cpus"</span>,
			<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
			scalar: <span class="o">{</span>
				value: 0.3
			<span class="o">}</span>,
			ranges: null,
			<span class="nb">set</span>: null,
			role: <span class="s2">"hdfs-role"</span>,
			reservation: <span class="o">{</span>
				principal: <span class="s2">"hdfs-principal"</span>,
				labels: <span class="o">{</span>
					labels: <span class="o">[{</span>
						key: <span class="s2">"resource_id"</span>,
						value: <span class="s2">"4208f1ea-586f-4157-81fd-dfa0877e7472"</span>
					<span class="o">}]</span>
				<span class="o">}</span>
			<span class="o">}</span>,
			disk: null,
			revocable: null,
			shared: null
		<span class="o">}</span>, <span class="o">{</span>
			name: <span class="s2">"mem"</span>,
			<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
			scalar: <span class="o">{</span>
				value: 512
			<span class="o">}</span>,
			ranges: null,
			<span class="nb">set</span>: null,
			role: <span class="s2">"hdfs-role"</span>,
			reservation: <span class="o">{</span>
				principal: <span class="s2">"hdfs-principal"</span>,
				labels: <span class="o">{</span>
					labels: <span class="o">[{</span>
						key: <span class="s2">"resource_id"</span>,
						value: <span class="s2">"a0be3c2c-3c7c-47ad-baa9-be81fb5d5f2e"</span>
					<span class="o">}]</span>
				<span class="o">}</span>
			<span class="o">}</span>,
			disk: null,
			revocable: null,
			shared: null
		<span class="o">}</span>, <span class="o">{</span>
			name: <span class="s2">"ports"</span>,
			<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
			scalar: null,
			ranges: <span class="o">{</span>
				range: <span class="o">[{</span>
					begin: 8480,
					end: 8480
				<span class="o">}</span>, <span class="o">{</span>
					begin: 8485,
					end: 8485
				<span class="o">}]</span>
			<span class="o">}</span>,
			<span class="nb">set</span>: null,
			role: <span class="s2">"hdfs-role"</span>,
			reservation: <span class="o">{</span>
				principal: <span class="s2">"hdfs-principal"</span>,
				labels: <span class="o">{</span>
					labels: <span class="o">[{</span>
						key: <span class="s2">"resource_id"</span>,
						value: <span class="s2">"d50b3deb-97c7-4960-89e5-ac4e508e4564"</span>
					<span class="o">}]</span>
				<span class="o">}</span>
			<span class="o">}</span>,
			disk: null,
			revocable: null,
			shared: null
		<span class="o">}</span>, <span class="o">{</span>
			name: <span class="s2">"disk"</span>,
			<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
			scalar: <span class="o">{</span>
				value: 5000
			<span class="o">}</span>,
			ranges: null,
			<span class="nb">set</span>: null,
			role: <span class="s2">"hdfs-role"</span>,
			reservation: <span class="o">{</span>
				principal: <span class="s2">"hdfs-principal"</span>,
				labels: <span class="o">{</span>
					labels: <span class="o">[{</span>
						key: <span class="s2">"resource_id"</span>,
						value: <span class="s2">"3e624468-11fb-4fcf-9e67-ddb883b1718e"</span>
					<span class="o">}]</span>
				<span class="o">}</span>
			<span class="o">}</span>,
			disk: <span class="o">{</span>
				persistence: <span class="o">{</span>
					id: <span class="s2">"6bf7fcf1-ccdf-41a3-87ba-459162da1f03"</span>,
					principal: <span class="s2">"hdfs-principal"</span>
				<span class="o">}</span>,
				volume: <span class="o">{</span>
					mode: <span class="s2">"RW"</span>,
					containerPath: <span class="s2">"journal-data"</span>,
					hostPath: null,
					image: null,
					<span class="nb">source</span>: null
				<span class="o">}</span>,
				<span class="nb">source</span>: null
			<span class="o">}</span>,
			revocable: null,
			shared: null
		<span class="o">}]</span>,
		executor: <span class="o">{</span>
			<span class="nb">type</span>: null,
			executorId: <span class="o">{</span>
				value: <span class="s2">"journal__e42893b5-9d96-4dfb-8e85-8360d483a122"</span>
			<span class="o">}</span>,
			frameworkId: null,
			<span class="nb">command</span>: <span class="o">{</span>
				uris: <span class="o">[{</span>
					value: <span class="s2">"https://downloads.mesosphere.com/hdfs/assets/1.0.0-2.6.0/executor.zip"</span>,
					executable: null,
					extract: null,
					cache: null,
					outputFile: null
				<span class="o">}</span>, <span class="o">{</span>
					value: <span class="s2">"https://downloads.mesosphere.com/libmesos-bundle/libmesos-bundle-1.9-argus-1.1.x-2.tar.gz"</span>,
					executable: null,
					extract: null,
					cache: null,
					outputFile: null
				<span class="o">}</span>, <span class="o">{</span>
					value: <span class="s2">"https://downloads.mesosphere.com/java/jre-8u112-linux-x64-jce-unlimited.tar.gz"</span>,
					executable: null,
					extract: null,
					cache: null,
					outputFile: null
				<span class="o">}</span>, <span class="o">{</span>
					value: <span class="s2">"https://downloads.mesosphere.com/hdfs/assets/hadoop-2.6.0-cdh5.9.1-dcos.tar.gz"</span>,
					executable: null,
					extract: null,
					cache: null,
					outputFile: null
				<span class="o">}</span>, <span class="o">{</span>
					value: <span class="s2">"https://downloads.mesosphere.com/hdfs/assets/1.0.0-2.6.0/bootstrap.zip"</span>,
					executable: null,
					extract: null,
					cache: null,
					outputFile: null
				<span class="o">}</span>, <span class="o">{</span>
					value: <span class="s2">"http://api.hdfs.marathon.l4lb.thisdcos.directory/v1/artifacts/template/25f791d8-4d42-458f-84fb-9d82842ffb3e/journal/node/core-site"</span>,
					executable: null,
					extract: <span class="nb">false</span>,
					cache: null,
					outputFile: <span class="s2">"config-templates/core-site"</span>
				<span class="o">}</span>, <span class="o">{</span>
					value: <span class="s2">"http://api.hdfs.marathon.l4lb.thisdcos.directory/v1/artifacts/template/25f791d8-4d42-458f-84fb-9d82842ffb3e/journal/node/hdfs-site"</span>,
					executable: null,
					extract: <span class="nb">false</span>,
					cache: null,
					outputFile: <span class="s2">"config-templates/hdfs-site"</span>
				<span class="o">}</span>, <span class="o">{</span>
					value: <span class="s2">"http://api.hdfs.marathon.l4lb.thisdcos.directory/v1/artifacts/template/25f791d8-4d42-458f-84fb-9d82842ffb3e/journal/node/hadoop-metrics2"</span>,
					executable: null,
					extract: <span class="nb">false</span>,
					cache: null,
					outputFile: <span class="s2">"config-templates/hadoop-metrics2"</span>
				<span class="o">}]</span>,
				environment: null,
				shell: null,
				value: <span class="s2">"export LD_LIBRARY_PATH=</span><span class="nv">$MESOS_SANDBOX</span><span class="s2">/libmesos-bundle/lib:</span><span class="nv">$LD_LIBRARY_PATH</span><span class="s2"> &amp;&amp; export MESOS_NATIVE_JAVA_LIBRARY=</span><span class="k">$(</span>ls <span class="nv">$MESOS_SANDBOX</span>/libmesos-bundle/lib/libmesos-<span class="k">*</span>.so<span class="k">)</span><span class="s2"> &amp;&amp; export JAVA_HOME=</span><span class="k">$(</span>ls -d <span class="nv">$MESOS_SANDBOX</span>/jre<span class="k">*</span>/<span class="k">)</span><span class="s2"> &amp;&amp; ./executor/bin/executor"</span>,
				arguments: <span class="o">[]</span>,
				user: null
			<span class="o">}</span>,
			container: null,
			resources: <span class="o">[]</span>,
			name: <span class="s2">"journal"</span>,
			<span class="nb">source</span>: null,
			data: null,
			discovery: null,
			shutdownGracePeriod: null,
			labels: null
		<span class="o">}</span>,
		<span class="nb">command</span>: <span class="o">{</span>
			uris: <span class="o">[]</span>,
			environment: <span class="o">{</span>
				variables: <span class="o">[{</span>
					name: <span class="s2">"PERMISSIONS_ENABLED"</span>,
					value: <span class="s2">"false"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"DATA_NODE_BALANCE_BANDWIDTH_PER_SEC"</span>,
					value: <span class="s2">"41943040"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"NAME_NODE_HANDLER_COUNT"</span>,
					value: <span class="s2">"20"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE"</span>,
					value: <span class="s2">"1000"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"HADOOP_ROOT_LOGGER"</span>,
					value: <span class="s2">"INFO,console"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"HA_FENCING_METHODS"</span>,
					value: <span class="s2">"shell(/bin/true)"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"SERVICE_ZK_ROOT"</span>,
					value: <span class="s2">"dcos-service-hdfs"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"HADOOP_PROXYUSER_HUE_GROUPS"</span>,
					value: <span class="s2">"*"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"NAME_NODE_HEARTBEAT_RECHECK_INTERVAL"</span>,
					value: <span class="s2">"60000"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"HADOOP_PROXYUSER_HUE_HOSTS"</span>,
					value: <span class="s2">"*"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS"</span>,
					value: <span class="s2">"1000"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"JOURNAL_NODE_RPC_PORT"</span>,
					value: <span class="s2">"8485"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"CLIENT_FAILOVER_PROXY_PROVIDER_HDFS"</span>,
					value: <span class="s2">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"DATA_NODE_HANDLER_COUNT"</span>,
					value: <span class="s2">"10"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"HA_AUTOMATIC_FAILURE"</span>,
					value: <span class="s2">"true"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"JOURNALNODE"</span>,
					value: <span class="s2">"true"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION"</span>,
					value: <span class="s2">"4"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"HADOOP_PROXYUSER_HTTPFS_HOSTS"</span>,
					value: <span class="s2">"*"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"POD_INSTANCE_INDEX"</span>,
					value: <span class="s2">"0"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"DATA_NODE_IPC_PORT"</span>,
					value: <span class="s2">"9005"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"JOURNAL_NODE_HTTP_PORT"</span>,
					value: <span class="s2">"8480"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK"</span>,
					value: <span class="s2">"false"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"TASK_USER"</span>,
					value: <span class="s2">"root"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"journal-0-node"</span>,
					value: <span class="s2">"true"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"HADOOP_PROXYUSER_ROOT_GROUPS"</span>,
					value: <span class="s2">"*"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"TASK_NAME"</span>,
					value: <span class="s2">"journal-0-node"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"HADOOP_PROXYUSER_ROOT_HOSTS"</span>,
					value: <span class="s2">"*"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"IMAGE_COMPRESS"</span>,
					value: <span class="s2">"true"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"CLIENT_READ_SHORTCIRCUIT"</span>,
					value: <span class="s2">"true"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"FRAMEWORK_NAME"</span>,
					value: <span class="s2">"hdfs"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"IMAGE_COMPRESSION_CODEC"</span>,
					value: <span class="s2">"org.apache.hadoop.io.compress.SnappyCodec"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"NAME_NODE_SAFEMODE_THRESHOLD_PCT"</span>,
					value: <span class="s2">"0.9"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION"</span>,
					value: <span class="s2">"0.95"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"HADOOP_PROXYUSER_HTTPFS_GROUPS"</span>,
					value: <span class="s2">"*"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"CLIENT_READ_SHORTCIRCUIT_PATH"</span>,
					value: <span class="s2">"dn_socket"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"DATA_NODE_HTTP_PORT"</span>,
					value: <span class="s2">"9004"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"DATA_NODE_RPC_PORT"</span>,
					value: <span class="s2">"9003"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"NAME_NODE_HTTP_PORT"</span>,
					value: <span class="s2">"9002"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"NAME_NODE_RPC_PORT"</span>,
					value: <span class="s2">"9001"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"CONFIG_TEMPLATE_CORE_SITE"</span>,
					value: <span class="s2">"config-templates/core-site,hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"CONFIG_TEMPLATE_HDFS_SITE"</span>,
					value: <span class="s2">"config-templates/hdfs-site,hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"CONFIG_TEMPLATE_HADOOP_METRICS2"</span>,
					value: <span class="s2">"config-templates/hadoop-metrics2,hadoop-2.6.0-cdh5.9.1/etc/hadoop/hadoop-metrics2.properties"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"PORT_JOURNAL_RPC"</span>,
					value: <span class="s2">"8485"</span>
				<span class="o">}</span>, <span class="o">{</span>
					name: <span class="s2">"PORT_JOURNAL_HTTP"</span>,
					value: <span class="s2">"8480"</span>
				<span class="o">}]</span>
			<span class="o">}</span>,
			shell: null,
			value: <span class="s2">"./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs journalnode"</span>,
			arguments: <span class="o">[]</span>,
			user: null
		<span class="o">}</span>,
		container: null,
		healthCheck: null,
		killPolicy: null,
		data: null,
		labels: <span class="o">{</span>
			labels: <span class="o">[{</span>
				key: <span class="s2">"goal_state"</span>,
				value: <span class="s2">"RUNNING"</span>
			<span class="o">}</span>, <span class="o">{</span>
				key: <span class="s2">"offer_attributes"</span>,
				value: <span class="s2">""</span>
			<span class="o">}</span>, <span class="o">{</span>
				key: <span class="s2">"task_type"</span>,
				value: <span class="s2">"journal"</span>
			<span class="o">}</span>, <span class="o">{</span>
				key: <span class="s2">"index"</span>,
				value: <span class="s2">"0"</span>
			<span class="o">}</span>, <span class="o">{</span>
				key: <span class="s2">"offer_hostname"</span>,
				value: <span class="s2">"10.0.1.23"</span>
			<span class="o">}</span>, <span class="o">{</span>
				key: <span class="s2">"target_configuration"</span>,
				value: <span class="s2">"4bdb3f97-96b0-4e78-8d47-f39edc33f6e3"</span>
			<span class="o">}]</span>
		<span class="o">}</span>,
		discovery: null
	<span class="o">}</span>,
	status: <span class="o">{</span>
		taskId: <span class="o">{</span>
			value: <span class="s2">"journal-0-node__b31a70f4-73c5-4065-990c-76c0c704b8e4"</span>
		<span class="o">}</span>,
		state: <span class="s2">"TASK_RUNNING"</span>,
		message: <span class="s2">"Reconciliation: Latest task state"</span>,
		<span class="nb">source</span>: <span class="s2">"SOURCE_MASTER"</span>,
		reason: <span class="s2">"REASON_RECONCILIATION"</span>,
		data: null,
		slaveId: <span class="o">{</span>
			value: <span class="s2">"0060634a-aa2b-4fcc-afa6-5569716b533a-S5"</span>
		<span class="o">}</span>,
		executorId: null,
		timestamp: 1486694618.923135,
		uuid: null,
		healthy: null,
		labels: null,
		containerStatus: <span class="o">{</span>
			containerId: <span class="o">{</span>
				value: <span class="s2">"a4c8433f-2648-4ba7-a8b8-5fe5df20e8af"</span>,
				parent: null
			<span class="o">}</span>,
			networkInfos: <span class="o">[{</span>
				ipAddresses: <span class="o">[{</span>
					protocol: null,
					ipAddress: <span class="s2">"10.0.1.23"</span>
				<span class="o">}]</span>,
				name: null,
				groups: <span class="o">[]</span>,
				labels: null,
				portMappings: <span class="o">[]</span>
			<span class="o">}]</span>,
			cgroupInfo: null,
			executorPid: 5594
		<span class="o">}</span>,
		unreachableTime: null
	<span class="o">}</span>
<span class="o">}]</span>
</code></pre>
</div>

<h2 id="replace-a-node">Replace a Node</h2>

<p>The replace endpoint can be used to replace a node with an instance running on another agent node.</p>

<p>CLI Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>dcos beta-hdfs --name<span class="o">=</span>hdfs pod replace &lt;node-id&gt;
</code></pre>
</div>

<p>HTTP Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl -X POST -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/pod/&lt;node-id&gt;/replace
</code></pre>
</div>

<p>If the operation succeeds, a <code class="highlighter-rouge">200 OK</code> is returned.</p>

<h2 id="restart-a-node">Restart a Node</h2>

<p>The restart endpoint can be used to restart a node in place on the same agent node.</p>

<p>CLI Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>dcos beta-hdfs pod --name<span class="o">=</span>hdfs restart &lt;node-id&gt;
</code></pre>
</div>

<p>HTTP Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl -X POST -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/pod/&lt;node-id&gt;/restart
</code></pre>
</div>

<p>If the operation succeeds a <code class="highlighter-rouge">200 OK</code> is returned.</p>

<h2 id="pause-a-node">Pause a Node</h2>

<p>The pause endpoint can be used to relaunch a node in an idle command state for debugging purposes.</p>

<p>CLI example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>dcos beta-hdfs debug pod pause &lt;node-id&gt;
</code></pre>
</div>

<p>HTTP Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl -X POST -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/pod/&lt;node-id&gt;/pause
</code></pre>
</div>

<h1 id="configuration-api">Configuration API</h1>

<p>The configuration API provides an endpoint to view current and previous configurations of the cluster.</p>

<h2 id="view-target-config">View Target Config</h2>

<p>You can view the current target configuration by sending a GET request to <code class="highlighter-rouge">/v1/configurations/target</code>.</p>

<p>CLI Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>dcos beta-hdfs config --name<span class="o">=</span>hdfs target
</code></pre>
</div>

<p>HTTP Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/configurations/target
<span class="o">{</span>
	name: <span class="s2">"hdfs"</span>,
	role: <span class="s2">"hdfs-role"</span>,
	principal: <span class="s2">"hdfs-principal"</span>,
	api - port: 10002,
	web - url: null,
	zookeeper: <span class="s2">"master.mesos:2181"</span>,
	pod - specs: <span class="o">[{</span>
		<span class="nb">type</span>: <span class="s2">"journal"</span>,
		user: null,
		count: 3,
		container: null,
		uris: <span class="o">[</span>
			<span class="s2">"https://downloads.mesosphere.com/hdfs/assets/hadoop-2.6.0-cdh5.9.1-dcos.tar.gz"</span>,
			<span class="s2">"https://downloads.mesosphere.com/hdfs/assets/1.0.0-2.6.0/bootstrap.zip"</span>
		<span class="o">]</span>,
		task - specs: <span class="o">[{</span>
			name: <span class="s2">"node"</span>,
			goal: <span class="s2">"RUNNING"</span>,
			resource - <span class="nb">set</span>: <span class="o">{</span>
				id: <span class="s2">"node-resource-set"</span>,
				resource - specifications: <span class="o">[{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"cpus"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 0.3
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}</span>, <span class="o">{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"mem"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 512
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}</span>, <span class="o">{</span>
					@type: <span class="s2">"PortsSpec"</span>,
					name: <span class="s2">"ports"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
						scalar: null,
						ranges: <span class="o">{</span>
							range: <span class="o">[{</span>
								begin: 8485,
								end: 8485
							<span class="o">}</span>, <span class="o">{</span>
								begin: 8480,
								end: 8480
							<span class="o">}]</span>
						<span class="o">}</span>,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					port - specs: <span class="o">[{</span>
						@type: <span class="s2">"PortSpec"</span>,
						name: <span class="s2">"ports"</span>,
						value: <span class="o">{</span>
							<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
							scalar: null,
							ranges: <span class="o">{</span>
								range: <span class="o">[{</span>
									begin: 8485,
									end: 8485
								<span class="o">}]</span>
							<span class="o">}</span>,
							<span class="nb">set</span>: null,
							text: null
						<span class="o">}</span>,
						role: <span class="s2">"hdfs-role"</span>,
						principal: <span class="s2">"hdfs-principal"</span>,
						port - name: <span class="s2">"journal-rpc"</span>,
						envKey: null
					<span class="o">}</span>, <span class="o">{</span>
						@type: <span class="s2">"PortSpec"</span>,
						name: <span class="s2">"ports"</span>,
						value: <span class="o">{</span>
							<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
							scalar: null,
							ranges: <span class="o">{</span>
								range: <span class="o">[{</span>
									begin: 8480,
									end: 8480
								<span class="o">}]</span>
							<span class="o">}</span>,
							<span class="nb">set</span>: null,
							text: null
						<span class="o">}</span>,
						role: <span class="s2">"hdfs-role"</span>,
						principal: <span class="s2">"hdfs-principal"</span>,
						port - name: <span class="s2">"journal-http"</span>,
						envKey: null
					<span class="o">}]</span>,
					envKey: null
				<span class="o">}]</span>,
				volume - specifications: <span class="o">[{</span>
					@type: <span class="s2">"DefaultVolumeSpec"</span>,
					<span class="nb">type</span>: <span class="s2">"ROOT"</span>,
					container - path: <span class="s2">"journal-data"</span>,
					name: <span class="s2">"disk"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 5000
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: <span class="s2">"DISK_SIZE"</span>
				<span class="o">}]</span>,
				role: <span class="s2">"hdfs-role"</span>,
				principal: <span class="s2">"hdfs-principal"</span>
			<span class="o">}</span>,
			<span class="nb">command</span> - spec: <span class="o">{</span>
				value: <span class="s2">"./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs journalnode"</span>,
				environment: <span class="o">{</span>
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: <span class="s2">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>,
					CLIENT_READ_SHORTCIRCUIT: <span class="s2">"true"</span>,
					CLIENT_READ_SHORTCIRCUIT_PATH: <span class="s2">"dn_socket"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: <span class="s2">"1000"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: <span class="s2">"1000"</span>,
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: <span class="s2">"41943040"</span>,
					DATA_NODE_HANDLER_COUNT: <span class="s2">"10"</span>,
					DATA_NODE_HTTP_PORT: <span class="s2">"9004"</span>,
					DATA_NODE_IPC_PORT: <span class="s2">"9005"</span>,
					DATA_NODE_RPC_PORT: <span class="s2">"9003"</span>,
					HADOOP_PROXYUSER_HTTPFS_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HTTPFS_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_HOSTS: <span class="s2">"*"</span>,
					HADOOP_ROOT_LOGGER: <span class="s2">"INFO,console"</span>,
					HA_AUTOMATIC_FAILURE: <span class="s2">"true"</span>,
					HA_FENCING_METHODS: <span class="s2">"shell(/bin/true)"</span>,
					IMAGE_COMPRESS: <span class="s2">"true"</span>,
					IMAGE_COMPRESSION_CODEC: <span class="s2">"org.apache.hadoop.io.compress.SnappyCodec"</span>,
					JOURNALNODE: <span class="s2">"true"</span>,
					JOURNAL_NODE_HTTP_PORT: <span class="s2">"8480"</span>,
					JOURNAL_NODE_RPC_PORT: <span class="s2">"8485"</span>,
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: <span class="s2">"false"</span>,
					NAME_NODE_HANDLER_COUNT: <span class="s2">"20"</span>,
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: <span class="s2">"60000"</span>,
					NAME_NODE_HTTP_PORT: <span class="s2">"9002"</span>,
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: <span class="s2">"0.95"</span>,
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: <span class="s2">"4"</span>,
					NAME_NODE_RPC_PORT: <span class="s2">"9001"</span>,
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: <span class="s2">"0.9"</span>,
					PERMISSIONS_ENABLED: <span class="s2">"false"</span>,
					SERVICE_ZK_ROOT: <span class="s2">"dcos-service-hdfs"</span>,
					TASK_USER: <span class="s2">"root"</span>
				<span class="o">}</span>
			<span class="o">}</span>,
			health - check - spec: null,
			readiness - check - spec: null,
			config - files: <span class="o">[{</span>
				name: <span class="s2">"core-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}</span>, <span class="o">{</span>
				name: <span class="s2">"hdfs-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ RULE:[1:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}</span>, <span class="o">{</span>
				name: <span class="s2">"hadoop-metrics2"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/hadoop-metrics2.properties"</span>,
				template - content: <span class="s2">"# Autogenerated by the Mesos Framework, DO NOT EDIT *.sink.statsd.class=org.apache.hadoop.metrics2.sink.StatsDSink journalnode.sink.statsd.period=10 journalnode.sink.statsd.server.host={{STATSD_UDP_HOST}} journalnode.sink.statsd.server.port={{STATSD_UDP_PORT}} journalnode.sink.statsd.skip.hostname=false"</span>
			<span class="o">}]</span>
		<span class="o">}]</span>,
		placement - rule: <span class="o">{</span>
			@type: <span class="s2">"AndRule"</span>,
			rules: <span class="o">[{</span>
				@type: <span class="s2">"TaskTypeRule"</span>,
				<span class="nb">type</span>: <span class="s2">"journal"</span>,
				converter: <span class="o">{</span>
					@type: <span class="s2">"TaskTypeLabelConverter"</span>
				<span class="o">}</span>,
				behavior: <span class="s2">"AVOID"</span>
			<span class="o">}</span>, <span class="o">{</span>
				@type: <span class="s2">"TaskTypeRule"</span>,
				<span class="nb">type</span>: <span class="s2">"name"</span>,
				converter: <span class="o">{</span>
					@type: <span class="s2">"TaskTypeLabelConverter"</span>
				<span class="o">}</span>,
				behavior: <span class="s2">"AVOID"</span>
			<span class="o">}]</span>
		<span class="o">}</span>
	<span class="o">}</span>, <span class="o">{</span>
		<span class="nb">type</span>: <span class="s2">"name"</span>,
		user: null,
		count: 2,
		container: null,
		uris: <span class="o">[</span>
			<span class="s2">"https://downloads.mesosphere.com/hdfs/assets/hadoop-2.6.0-cdh5.9.1-dcos.tar.gz"</span>,
			<span class="s2">"https://downloads.mesosphere.com/hdfs/assets/1.0.0-2.6.0/bootstrap.zip"</span>
		<span class="o">]</span>,
		task - specs: <span class="o">[{</span>
			name: <span class="s2">"node"</span>,
			goal: <span class="s2">"RUNNING"</span>,
			resource - <span class="nb">set</span>: <span class="o">{</span>
				id: <span class="s2">"name-resources"</span>,
				resource - specifications: <span class="o">[{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"cpus"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 0.3
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}</span>, <span class="o">{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"mem"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 512
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}</span>, <span class="o">{</span>
					@type: <span class="s2">"PortsSpec"</span>,
					name: <span class="s2">"ports"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
						scalar: null,
						ranges: <span class="o">{</span>
							range: <span class="o">[{</span>
								begin: 9001,
								end: 9001
							<span class="o">}</span>, <span class="o">{</span>
								begin: 9002,
								end: 9002
							<span class="o">}]</span>
						<span class="o">}</span>,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					port - specs: <span class="o">[{</span>
						@type: <span class="s2">"PortSpec"</span>,
						name: <span class="s2">"ports"</span>,
						value: <span class="o">{</span>
							<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
							scalar: null,
							ranges: <span class="o">{</span>
								range: <span class="o">[{</span>
									begin: 9001,
									end: 9001
								<span class="o">}]</span>
							<span class="o">}</span>,
							<span class="nb">set</span>: null,
							text: null
						<span class="o">}</span>,
						role: <span class="s2">"hdfs-role"</span>,
						principal: <span class="s2">"hdfs-principal"</span>,
						port - name: <span class="s2">"name-rpc"</span>,
						envKey: null
					<span class="o">}</span>, <span class="o">{</span>
						@type: <span class="s2">"PortSpec"</span>,
						name: <span class="s2">"ports"</span>,
						value: <span class="o">{</span>
							<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
							scalar: null,
							ranges: <span class="o">{</span>
								range: <span class="o">[{</span>
									begin: 9002,
									end: 9002
								<span class="o">}]</span>
							<span class="o">}</span>,
							<span class="nb">set</span>: null,
							text: null
						<span class="o">}</span>,
						role: <span class="s2">"hdfs-role"</span>,
						principal: <span class="s2">"hdfs-principal"</span>,
						port - name: <span class="s2">"name-http"</span>,
						envKey: null
					<span class="o">}]</span>,
					envKey: null
				<span class="o">}]</span>,
				volume - specifications: <span class="o">[{</span>
					@type: <span class="s2">"DefaultVolumeSpec"</span>,
					<span class="nb">type</span>: <span class="s2">"ROOT"</span>,
					container - path: <span class="s2">"name-data"</span>,
					name: <span class="s2">"disk"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 5000
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: <span class="s2">"DISK_SIZE"</span>
				<span class="o">}]</span>,
				role: <span class="s2">"hdfs-role"</span>,
				principal: <span class="s2">"hdfs-principal"</span>
			<span class="o">}</span>,
			<span class="nb">command</span> - spec: <span class="o">{</span>
				value: <span class="s2">"./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs namenode"</span>,
				environment: <span class="o">{</span>
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: <span class="s2">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>,
					CLIENT_READ_SHORTCIRCUIT: <span class="s2">"true"</span>,
					CLIENT_READ_SHORTCIRCUIT_PATH: <span class="s2">"dn_socket"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: <span class="s2">"1000"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: <span class="s2">"1000"</span>,
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: <span class="s2">"41943040"</span>,
					DATA_NODE_HANDLER_COUNT: <span class="s2">"10"</span>,
					DATA_NODE_HTTP_PORT: <span class="s2">"9004"</span>,
					DATA_NODE_IPC_PORT: <span class="s2">"9005"</span>,
					DATA_NODE_RPC_PORT: <span class="s2">"9003"</span>,
					FRAMEWORK_NAME: <span class="s2">""</span>,
					HADOOP_PROXYUSER_HTTPFS_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HTTPFS_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_HOSTS: <span class="s2">"*"</span>,
					HADOOP_ROOT_LOGGER: <span class="s2">"INFO,console"</span>,
					HA_AUTOMATIC_FAILURE: <span class="s2">"true"</span>,
					HA_FENCING_METHODS: <span class="s2">"shell(/bin/true)"</span>,
					IMAGE_COMPRESS: <span class="s2">"true"</span>,
					IMAGE_COMPRESSION_CODEC: <span class="s2">"org.apache.hadoop.io.compress.SnappyCodec"</span>,
					JOURNAL_NODE_HTTP_PORT: <span class="s2">"8480"</span>,
					JOURNAL_NODE_RPC_PORT: <span class="s2">"8485"</span>,
					NAMENODE: <span class="s2">"true"</span>,
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: <span class="s2">"false"</span>,
					NAME_NODE_HANDLER_COUNT: <span class="s2">"20"</span>,
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: <span class="s2">"60000"</span>,
					NAME_NODE_HTTP_PORT: <span class="s2">"9002"</span>,
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: <span class="s2">"0.95"</span>,
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: <span class="s2">"4"</span>,
					NAME_NODE_RPC_PORT: <span class="s2">"9001"</span>,
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: <span class="s2">"0.9"</span>,
					PERMISSIONS_ENABLED: <span class="s2">"false"</span>,
					SERVICE_ZK_ROOT: <span class="s2">"dcos-service-hdfs"</span>,
					TASK_USER: <span class="s2">"root"</span>
				<span class="o">}</span>
			<span class="o">}</span>,
			health - check - spec: null,
			readiness - check - spec: <span class="o">{</span>
				<span class="nb">command</span>: <span class="s2">"./hadoop-2.6.0-cdh5.9.1/bin/hdfs haadmin -getServiceState name-</span><span class="nv">$POD_INSTANCE_INDEX</span><span class="s2">-node"</span>,
				delay: 0,
				interval: 5,
				timeout: 60
			<span class="o">}</span>,
			config - files: <span class="o">[{</span>
				name: <span class="s2">"core-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}</span>, <span class="o">{</span>
				name: <span class="s2">"hdfs-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ RULE:[1:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}</span>, <span class="o">{</span>
				name: <span class="s2">"hadoop-metrics2"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/hadoop-metrics2.properties"</span>,
				template - content: <span class="s2">"# Autogenerated by the Mesos Framework, DO NOT EDIT *.sink.statsd.class=org.apache.hadoop.metrics2.sink.StatsDSink namenode.sink.statsd.period=10 namenode.sink.statsd.server.host={{STATSD_UDP_HOST}} namenode.sink.statsd.server.port={{STATSD_UDP_PORT}} namenode.sink.statsd.skip.hostname=false"</span>
			<span class="o">}]</span>
		<span class="o">}</span>, <span class="o">{</span>
			name: <span class="s2">"format"</span>,
			goal: <span class="s2">"ONCE"</span>,
			resource - <span class="nb">set</span>: <span class="o">{</span>
				id: <span class="s2">"name-resources"</span>,
				resource - specifications: <span class="o">[{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"cpus"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 0.3
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}</span>, <span class="o">{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"mem"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 512
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}</span>, <span class="o">{</span>
					@type: <span class="s2">"PortsSpec"</span>,
					name: <span class="s2">"ports"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
						scalar: null,
						ranges: <span class="o">{</span>
							range: <span class="o">[{</span>
								begin: 9001,
								end: 9001
							<span class="o">}</span>, <span class="o">{</span>
								begin: 9002,
								end: 9002
							<span class="o">}]</span>
						<span class="o">}</span>,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					port - specs: <span class="o">[{</span>
						@type: <span class="s2">"PortSpec"</span>,
						name: <span class="s2">"ports"</span>,
						value: <span class="o">{</span>
							<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
							scalar: null,
							ranges: <span class="o">{</span>
								range: <span class="o">[{</span>
									begin: 9001,
									end: 9001
								<span class="o">}]</span>
							<span class="o">}</span>,
							<span class="nb">set</span>: null,
							text: null
						<span class="o">}</span>,
						role: <span class="s2">"hdfs-role"</span>,
						principal: <span class="s2">"hdfs-principal"</span>,
						port - name: <span class="s2">"name-rpc"</span>,
						envKey: null
					<span class="o">}</span>, <span class="o">{</span>
						@type: <span class="s2">"PortSpec"</span>,
						name: <span class="s2">"ports"</span>,
						value: <span class="o">{</span>
							<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
							scalar: null,
							ranges: <span class="o">{</span>
								range: <span class="o">[{</span>
									begin: 9002,
									end: 9002
								<span class="o">}]</span>
							<span class="o">}</span>,
							<span class="nb">set</span>: null,
							text: null
						<span class="o">}</span>,
						role: <span class="s2">"hdfs-role"</span>,
						principal: <span class="s2">"hdfs-principal"</span>,
						port - name: <span class="s2">"name-http"</span>,
						envKey: null
					<span class="o">}]</span>,
					envKey: null
				<span class="o">}]</span>,
				volume - specifications: <span class="o">[{</span>
					@type: <span class="s2">"DefaultVolumeSpec"</span>,
					<span class="nb">type</span>: <span class="s2">"ROOT"</span>,
					container - path: <span class="s2">"name-data"</span>,
					name: <span class="s2">"disk"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 5000
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: <span class="s2">"DISK_SIZE"</span>
				<span class="o">}]</span>,
				role: <span class="s2">"hdfs-role"</span>,
				principal: <span class="s2">"hdfs-principal"</span>
			<span class="o">}</span>,
			<span class="nb">command</span> - spec: <span class="o">{</span>
				value: <span class="s2">"./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs namenode -format"</span>,
				environment: <span class="o">{</span>
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: <span class="s2">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>,
					CLIENT_READ_SHORTCIRCUIT: <span class="s2">"true"</span>,
					CLIENT_READ_SHORTCIRCUIT_PATH: <span class="s2">"dn_socket"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: <span class="s2">"1000"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: <span class="s2">"1000"</span>,
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: <span class="s2">"41943040"</span>,
					DATA_NODE_HANDLER_COUNT: <span class="s2">"10"</span>,
					DATA_NODE_HTTP_PORT: <span class="s2">"9004"</span>,
					DATA_NODE_IPC_PORT: <span class="s2">"9005"</span>,
					DATA_NODE_RPC_PORT: <span class="s2">"9003"</span>,
					FRAMEWORK_NAME: <span class="s2">""</span>,
					HADOOP_PROXYUSER_HTTPFS_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HTTPFS_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_HOSTS: <span class="s2">"*"</span>,
					HADOOP_ROOT_LOGGER: <span class="s2">"INFO,console"</span>,
					HA_AUTOMATIC_FAILURE: <span class="s2">"true"</span>,
					HA_FENCING_METHODS: <span class="s2">"shell(/bin/true)"</span>,
					IMAGE_COMPRESS: <span class="s2">"true"</span>,
					IMAGE_COMPRESSION_CODEC: <span class="s2">"org.apache.hadoop.io.compress.SnappyCodec"</span>,
					JOURNAL_NODE_HTTP_PORT: <span class="s2">"8480"</span>,
					JOURNAL_NODE_RPC_PORT: <span class="s2">"8485"</span>,
					NAMENODE: <span class="s2">"true"</span>,
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: <span class="s2">"false"</span>,
					NAME_NODE_HANDLER_COUNT: <span class="s2">"20"</span>,
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: <span class="s2">"60000"</span>,
					NAME_NODE_HTTP_PORT: <span class="s2">"9002"</span>,
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: <span class="s2">"0.95"</span>,
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: <span class="s2">"4"</span>,
					NAME_NODE_RPC_PORT: <span class="s2">"9001"</span>,
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: <span class="s2">"0.9"</span>,
					PERMISSIONS_ENABLED: <span class="s2">"false"</span>,
					SERVICE_ZK_ROOT: <span class="s2">"dcos-service-hdfs"</span>,
					TASK_USER: <span class="s2">"root"</span>
				<span class="o">}</span>
			<span class="o">}</span>,
			health - check - spec: null,
			readiness - check - spec: null,
			config - files: <span class="o">[{</span>
				name: <span class="s2">"core-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}</span>, <span class="o">{</span>
				name: <span class="s2">"hdfs-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ RULE:[1:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}]</span>
		<span class="o">}</span>, <span class="o">{</span>
			name: <span class="s2">"bootstrap"</span>,
			goal: <span class="s2">"ONCE"</span>,
			resource - <span class="nb">set</span>: <span class="o">{</span>
				id: <span class="s2">"name-resources"</span>,
				resource - specifications: <span class="o">[{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"cpus"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 0.3
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}</span>, <span class="o">{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"mem"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 512
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}</span>, <span class="o">{</span>
					@type: <span class="s2">"PortsSpec"</span>,
					name: <span class="s2">"ports"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
						scalar: null,
						ranges: <span class="o">{</span>
							range: <span class="o">[{</span>
								begin: 9001,
								end: 9001
							<span class="o">}</span>, <span class="o">{</span>
								begin: 9002,
								end: 9002
							<span class="o">}]</span>
						<span class="o">}</span>,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					port - specs: <span class="o">[{</span>
						@type: <span class="s2">"PortSpec"</span>,
						name: <span class="s2">"ports"</span>,
						value: <span class="o">{</span>
							<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
							scalar: null,
							ranges: <span class="o">{</span>
								range: <span class="o">[{</span>
									begin: 9001,
									end: 9001
								<span class="o">}]</span>
							<span class="o">}</span>,
							<span class="nb">set</span>: null,
							text: null
						<span class="o">}</span>,
						role: <span class="s2">"hdfs-role"</span>,
						principal: <span class="s2">"hdfs-principal"</span>,
						port - name: <span class="s2">"name-rpc"</span>,
						envKey: null
					<span class="o">}</span>, <span class="o">{</span>
						@type: <span class="s2">"PortSpec"</span>,
						name: <span class="s2">"ports"</span>,
						value: <span class="o">{</span>
							<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
							scalar: null,
							ranges: <span class="o">{</span>
								range: <span class="o">[{</span>
									begin: 9002,
									end: 9002
								<span class="o">}]</span>
							<span class="o">}</span>,
							<span class="nb">set</span>: null,
							text: null
						<span class="o">}</span>,
						role: <span class="s2">"hdfs-role"</span>,
						principal: <span class="s2">"hdfs-principal"</span>,
						port - name: <span class="s2">"name-http"</span>,
						envKey: null
					<span class="o">}]</span>,
					envKey: null
				<span class="o">}]</span>,
				volume - specifications: <span class="o">[{</span>
					@type: <span class="s2">"DefaultVolumeSpec"</span>,
					<span class="nb">type</span>: <span class="s2">"ROOT"</span>,
					container - path: <span class="s2">"name-data"</span>,
					name: <span class="s2">"disk"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 5000
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: <span class="s2">"DISK_SIZE"</span>
				<span class="o">}]</span>,
				role: <span class="s2">"hdfs-role"</span>,
				principal: <span class="s2">"hdfs-principal"</span>
			<span class="o">}</span>,
			<span class="nb">command</span> - spec: <span class="o">{</span>
				value: <span class="s2">"./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs namenode -bootstrapStandby"</span>,
				environment: <span class="o">{</span>
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: <span class="s2">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>,
					CLIENT_READ_SHORTCIRCUIT: <span class="s2">"true"</span>,
					CLIENT_READ_SHORTCIRCUIT_PATH: <span class="s2">"dn_socket"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: <span class="s2">"1000"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: <span class="s2">"1000"</span>,
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: <span class="s2">"41943040"</span>,
					DATA_NODE_HANDLER_COUNT: <span class="s2">"10"</span>,
					DATA_NODE_HTTP_PORT: <span class="s2">"9004"</span>,
					DATA_NODE_IPC_PORT: <span class="s2">"9005"</span>,
					DATA_NODE_RPC_PORT: <span class="s2">"9003"</span>,
					FRAMEWORK_NAME: <span class="s2">""</span>,
					HADOOP_PROXYUSER_HTTPFS_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HTTPFS_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_HOSTS: <span class="s2">"*"</span>,
					HADOOP_ROOT_LOGGER: <span class="s2">"INFO,console"</span>,
					HA_AUTOMATIC_FAILURE: <span class="s2">"true"</span>,
					HA_FENCING_METHODS: <span class="s2">"shell(/bin/true)"</span>,
					IMAGE_COMPRESS: <span class="s2">"true"</span>,
					IMAGE_COMPRESSION_CODEC: <span class="s2">"org.apache.hadoop.io.compress.SnappyCodec"</span>,
					JOURNAL_NODE_HTTP_PORT: <span class="s2">"8480"</span>,
					JOURNAL_NODE_RPC_PORT: <span class="s2">"8485"</span>,
					NAMENODE: <span class="s2">"true"</span>,
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: <span class="s2">"false"</span>,
					NAME_NODE_HANDLER_COUNT: <span class="s2">"20"</span>,
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: <span class="s2">"60000"</span>,
					NAME_NODE_HTTP_PORT: <span class="s2">"9002"</span>,
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: <span class="s2">"0.95"</span>,
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: <span class="s2">"4"</span>,
					NAME_NODE_RPC_PORT: <span class="s2">"9001"</span>,
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: <span class="s2">"0.9"</span>,
					PERMISSIONS_ENABLED: <span class="s2">"false"</span>,
					SERVICE_ZK_ROOT: <span class="s2">"dcos-service-hdfs"</span>,
					TASK_USER: <span class="s2">"root"</span>
				<span class="o">}</span>
			<span class="o">}</span>,
			health - check - spec: null,
			readiness - check - spec: null,
			config - files: <span class="o">[{</span>
				name: <span class="s2">"core-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}</span>, <span class="o">{</span>
				name: <span class="s2">"hdfs-bootstrap-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ RULE:[1:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}]</span>
		<span class="o">}]</span>,
		placement - rule: <span class="o">{</span>
			@type: <span class="s2">"AndRule"</span>,
			rules: <span class="o">[{</span>
				@type: <span class="s2">"TaskTypeRule"</span>,
				<span class="nb">type</span>: <span class="s2">"name"</span>,
				converter: <span class="o">{</span>
					@type: <span class="s2">"TaskTypeLabelConverter"</span>
				<span class="o">}</span>,
				behavior: <span class="s2">"AVOID"</span>
			<span class="o">}</span>, <span class="o">{</span>
				@type: <span class="s2">"TaskTypeRule"</span>,
				<span class="nb">type</span>: <span class="s2">"journal"</span>,
				converter: <span class="o">{</span>
					@type: <span class="s2">"TaskTypeLabelConverter"</span>
				<span class="o">}</span>,
				behavior: <span class="s2">"AVOID"</span>
			<span class="o">}]</span>
		<span class="o">}</span>
	<span class="o">}</span>, <span class="o">{</span>
		<span class="nb">type</span>: <span class="s2">"zkfc"</span>,
		user: null,
		count: 2,
		container: null,
		uris: <span class="o">[</span>
			<span class="s2">"https://downloads.mesosphere.com/hdfs/assets/hadoop-2.6.0-cdh5.9.1-dcos.tar.gz"</span>,
			<span class="s2">"https://downloads.mesosphere.com/hdfs/assets/1.0.0-2.6.0/bootstrap.zip"</span>
		<span class="o">]</span>,
		task - specs: <span class="o">[{</span>
			name: <span class="s2">"node"</span>,
			goal: <span class="s2">"RUNNING"</span>,
			resource - <span class="nb">set</span>: <span class="o">{</span>
				id: <span class="s2">"zkfc-resources"</span>,
				resource - specifications: <span class="o">[{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"cpus"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 0.3
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}</span>, <span class="o">{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"mem"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 512
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}]</span>,
				volume - specifications: <span class="o">[]</span>,
				role: <span class="s2">"hdfs-role"</span>,
				principal: <span class="s2">"hdfs-principal"</span>
			<span class="o">}</span>,
			<span class="nb">command</span> - spec: <span class="o">{</span>
				value: <span class="s2">"./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs zkfc"</span>,
				environment: <span class="o">{</span>
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: <span class="s2">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>,
					CLIENT_READ_SHORTCIRCUIT: <span class="s2">"true"</span>,
					CLIENT_READ_SHORTCIRCUIT_PATH: <span class="s2">"dn_socket"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: <span class="s2">"1000"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: <span class="s2">"1000"</span>,
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: <span class="s2">"41943040"</span>,
					DATA_NODE_HANDLER_COUNT: <span class="s2">"10"</span>,
					DATA_NODE_HTTP_PORT: <span class="s2">"9004"</span>,
					DATA_NODE_IPC_PORT: <span class="s2">"9005"</span>,
					DATA_NODE_RPC_PORT: <span class="s2">"9003"</span>,
					HADOOP_PROXYUSER_HTTPFS_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HTTPFS_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_HOSTS: <span class="s2">"*"</span>,
					HADOOP_ROOT_LOGGER: <span class="s2">"INFO,console"</span>,
					HA_AUTOMATIC_FAILURE: <span class="s2">"true"</span>,
					HA_FENCING_METHODS: <span class="s2">"shell(/bin/true)"</span>,
					IMAGE_COMPRESS: <span class="s2">"true"</span>,
					IMAGE_COMPRESSION_CODEC: <span class="s2">"org.apache.hadoop.io.compress.SnappyCodec"</span>,
					JOURNAL_NODE_HTTP_PORT: <span class="s2">"8480"</span>,
					JOURNAL_NODE_RPC_PORT: <span class="s2">"8485"</span>,
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: <span class="s2">"false"</span>,
					NAME_NODE_HANDLER_COUNT: <span class="s2">"20"</span>,
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: <span class="s2">"60000"</span>,
					NAME_NODE_HTTP_PORT: <span class="s2">"9002"</span>,
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: <span class="s2">"0.95"</span>,
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: <span class="s2">"4"</span>,
					NAME_NODE_RPC_PORT: <span class="s2">"9001"</span>,
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: <span class="s2">"0.9"</span>,
					PERMISSIONS_ENABLED: <span class="s2">"false"</span>,
					SERVICE_ZK_ROOT: <span class="s2">"dcos-service-hdfs"</span>,
					TASK_USER: <span class="s2">"root"</span>,
					ZKFC: <span class="s2">"true"</span>
				<span class="o">}</span>
			<span class="o">}</span>,
			health - check - spec: null,
			readiness - check - spec: null,
			config - files: <span class="o">[{</span>
				name: <span class="s2">"core-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}</span>, <span class="o">{</span>
				name: <span class="s2">"hdfs-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ RULE:[1:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}]</span>
		<span class="o">}</span>, <span class="o">{</span>
			name: <span class="s2">"format"</span>,
			goal: <span class="s2">"ONCE"</span>,
			resource - <span class="nb">set</span>: <span class="o">{</span>
				id: <span class="s2">"zkfc-resources"</span>,
				resource - specifications: <span class="o">[{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"cpus"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 0.3
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}</span>, <span class="o">{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"mem"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 512
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}]</span>,
				volume - specifications: <span class="o">[]</span>,
				role: <span class="s2">"hdfs-role"</span>,
				principal: <span class="s2">"hdfs-principal"</span>
			<span class="o">}</span>,
			<span class="nb">command</span> - spec: <span class="o">{</span>
				value: <span class="s2">"./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs zkfc -formatZK"</span>,
				environment: <span class="o">{</span>
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: <span class="s2">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>,
					CLIENT_READ_SHORTCIRCUIT: <span class="s2">"true"</span>,
					CLIENT_READ_SHORTCIRCUIT_PATH: <span class="s2">"dn_socket"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: <span class="s2">"1000"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: <span class="s2">"1000"</span>,
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: <span class="s2">"41943040"</span>,
					DATA_NODE_HANDLER_COUNT: <span class="s2">"10"</span>,
					DATA_NODE_HTTP_PORT: <span class="s2">"9004"</span>,
					DATA_NODE_IPC_PORT: <span class="s2">"9005"</span>,
					DATA_NODE_RPC_PORT: <span class="s2">"9003"</span>,
					HADOOP_PROXYUSER_HTTPFS_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HTTPFS_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_HOSTS: <span class="s2">"*"</span>,
					HADOOP_ROOT_LOGGER: <span class="s2">"INFO,console"</span>,
					HA_AUTOMATIC_FAILURE: <span class="s2">"true"</span>,
					HA_FENCING_METHODS: <span class="s2">"shell(/bin/true)"</span>,
					IMAGE_COMPRESS: <span class="s2">"true"</span>,
					IMAGE_COMPRESSION_CODEC: <span class="s2">"org.apache.hadoop.io.compress.SnappyCodec"</span>,
					JOURNAL_NODE_HTTP_PORT: <span class="s2">"8480"</span>,
					JOURNAL_NODE_RPC_PORT: <span class="s2">"8485"</span>,
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: <span class="s2">"false"</span>,
					NAME_NODE_HANDLER_COUNT: <span class="s2">"20"</span>,
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: <span class="s2">"60000"</span>,
					NAME_NODE_HTTP_PORT: <span class="s2">"9002"</span>,
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: <span class="s2">"0.95"</span>,
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: <span class="s2">"4"</span>,
					NAME_NODE_RPC_PORT: <span class="s2">"9001"</span>,
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: <span class="s2">"0.9"</span>,
					PERMISSIONS_ENABLED: <span class="s2">"false"</span>,
					SERVICE_ZK_ROOT: <span class="s2">"dcos-service-hdfs"</span>,
					TASK_USER: <span class="s2">"root"</span>,
					ZKFC: <span class="s2">"true"</span>
				<span class="o">}</span>
			<span class="o">}</span>,
			health - check - spec: null,
			readiness - check - spec: null,
			config - files: <span class="o">[{</span>
				name: <span class="s2">"core-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}</span>, <span class="o">{</span>
				name: <span class="s2">"hdfs-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ RULE:[1:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}]</span>
		<span class="o">}]</span>,
		placement - rule: <span class="o">{</span>
			@type: <span class="s2">"AndRule"</span>,
			rules: <span class="o">[{</span>
				@type: <span class="s2">"TaskTypeRule"</span>,
				<span class="nb">type</span>: <span class="s2">"zkfc"</span>,
				converter: <span class="o">{</span>
					@type: <span class="s2">"TaskTypeLabelConverter"</span>
				<span class="o">}</span>,
				behavior: <span class="s2">"AVOID"</span>
			<span class="o">}</span>, <span class="o">{</span>
				@type: <span class="s2">"TaskTypeRule"</span>,
				<span class="nb">type</span>: <span class="s2">"name"</span>,
				converter: <span class="o">{</span>
					@type: <span class="s2">"TaskTypeLabelConverter"</span>
				<span class="o">}</span>,
				behavior: <span class="s2">"COLOCATE"</span>
			<span class="o">}]</span>
		<span class="o">}</span>
	<span class="o">}</span>, <span class="o">{</span>
		<span class="nb">type</span>: <span class="s2">"data"</span>,
		user: null,
		count: 3,
		container: null,
		uris: <span class="o">[</span>
			<span class="s2">"https://downloads.mesosphere.com/hdfs/assets/hadoop-2.6.0-cdh5.9.1-dcos.tar.gz"</span>,
			<span class="s2">"https://downloads.mesosphere.com/hdfs/assets/1.0.0-2.6.0/bootstrap.zip"</span>
		<span class="o">]</span>,
		task - specs: <span class="o">[{</span>
			name: <span class="s2">"node"</span>,
			goal: <span class="s2">"RUNNING"</span>,
			resource - <span class="nb">set</span>: <span class="o">{</span>
				id: <span class="s2">"node-resource-set"</span>,
				resource - specifications: <span class="o">[{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"cpus"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 0.3
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}</span>, <span class="o">{</span>
					@type: <span class="s2">"DefaultResourceSpec"</span>,
					name: <span class="s2">"mem"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 512
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: null
				<span class="o">}</span>, <span class="o">{</span>
					@type: <span class="s2">"PortsSpec"</span>,
					name: <span class="s2">"ports"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
						scalar: null,
						ranges: <span class="o">{</span>
							range: <span class="o">[{</span>
								begin: 9003,
								end: 9003
							<span class="o">}</span>, <span class="o">{</span>
								begin: 9004,
								end: 9004
							<span class="o">}</span>, <span class="o">{</span>
								begin: 9005,
								end: 9005
							<span class="o">}]</span>
						<span class="o">}</span>,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					port - specs: <span class="o">[{</span>
						@type: <span class="s2">"PortSpec"</span>,
						name: <span class="s2">"ports"</span>,
						value: <span class="o">{</span>
							<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
							scalar: null,
							ranges: <span class="o">{</span>
								range: <span class="o">[{</span>
									begin: 9003,
									end: 9003
								<span class="o">}]</span>
							<span class="o">}</span>,
							<span class="nb">set</span>: null,
							text: null
						<span class="o">}</span>,
						role: <span class="s2">"hdfs-role"</span>,
						principal: <span class="s2">"hdfs-principal"</span>,
						port - name: <span class="s2">"data-rpc"</span>,
						envKey: null
					<span class="o">}</span>, <span class="o">{</span>
						@type: <span class="s2">"PortSpec"</span>,
						name: <span class="s2">"ports"</span>,
						value: <span class="o">{</span>
							<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
							scalar: null,
							ranges: <span class="o">{</span>
								range: <span class="o">[{</span>
									begin: 9004,
									end: 9004
								<span class="o">}]</span>
							<span class="o">}</span>,
							<span class="nb">set</span>: null,
							text: null
						<span class="o">}</span>,
						role: <span class="s2">"hdfs-role"</span>,
						principal: <span class="s2">"hdfs-principal"</span>,
						port - name: <span class="s2">"data-http"</span>,
						envKey: null
					<span class="o">}</span>, <span class="o">{</span>
						@type: <span class="s2">"PortSpec"</span>,
						name: <span class="s2">"ports"</span>,
						value: <span class="o">{</span>
							<span class="nb">type</span>: <span class="s2">"RANGES"</span>,
							scalar: null,
							ranges: <span class="o">{</span>
								range: <span class="o">[{</span>
									begin: 9005,
									end: 9005
								<span class="o">}]</span>
							<span class="o">}</span>,
							<span class="nb">set</span>: null,
							text: null
						<span class="o">}</span>,
						role: <span class="s2">"hdfs-role"</span>,
						principal: <span class="s2">"hdfs-principal"</span>,
						port - name: <span class="s2">"data-ipc"</span>,
						envKey: null
					<span class="o">}]</span>,
					envKey: null
				<span class="o">}]</span>,
				volume - specifications: <span class="o">[{</span>
					@type: <span class="s2">"DefaultVolumeSpec"</span>,
					<span class="nb">type</span>: <span class="s2">"ROOT"</span>,
					container - path: <span class="s2">"data-data"</span>,
					name: <span class="s2">"disk"</span>,
					value: <span class="o">{</span>
						<span class="nb">type</span>: <span class="s2">"SCALAR"</span>,
						scalar: <span class="o">{</span>
							value: 5000
						<span class="o">}</span>,
						ranges: null,
						<span class="nb">set</span>: null,
						text: null
					<span class="o">}</span>,
					role: <span class="s2">"hdfs-role"</span>,
					principal: <span class="s2">"hdfs-principal"</span>,
					envKey: <span class="s2">"DISK_SIZE"</span>
				<span class="o">}]</span>,
				role: <span class="s2">"hdfs-role"</span>,
				principal: <span class="s2">"hdfs-principal"</span>
			<span class="o">}</span>,
			<span class="nb">command</span> - spec: <span class="o">{</span>
				value: <span class="s2">"./bootstrap &amp;&amp; mkdir -p /var/lib/hadoop-hdfs &amp;&amp; chown root /var/lib/hadoop-hdfs &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs datanode "</span>,
				environment: <span class="o">{</span>
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: <span class="s2">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>,
					CLIENT_READ_SHORTCIRCUIT: <span class="s2">"true"</span>,
					CLIENT_READ_SHORTCIRCUIT_PATH: <span class="s2">"dn_socket"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: <span class="s2">"1000"</span>,
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: <span class="s2">"1000"</span>,
					DATANODE: <span class="s2">"true"</span>,
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: <span class="s2">"41943040"</span>,
					DATA_NODE_HANDLER_COUNT: <span class="s2">"10"</span>,
					DATA_NODE_HTTP_PORT: <span class="s2">"9004"</span>,
					DATA_NODE_IPC_PORT: <span class="s2">"9005"</span>,
					DATA_NODE_RPC_PORT: <span class="s2">"9003"</span>,
					FRAMEWORK_NAME: <span class="s2">""</span>,
					HADOOP_PROXYUSER_HTTPFS_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HTTPFS_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_HUE_HOSTS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_GROUPS: <span class="s2">"*"</span>,
					HADOOP_PROXYUSER_ROOT_HOSTS: <span class="s2">"*"</span>,
					HADOOP_ROOT_LOGGER: <span class="s2">"INFO,console"</span>,
					HA_AUTOMATIC_FAILURE: <span class="s2">"true"</span>,
					HA_FENCING_METHODS: <span class="s2">"shell(/bin/true)"</span>,
					IMAGE_COMPRESS: <span class="s2">"true"</span>,
					IMAGE_COMPRESSION_CODEC: <span class="s2">"org.apache.hadoop.io.compress.SnappyCodec"</span>,
					JOURNAL_NODE_HTTP_PORT: <span class="s2">"8480"</span>,
					JOURNAL_NODE_RPC_PORT: <span class="s2">"8485"</span>,
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: <span class="s2">"false"</span>,
					NAME_NODE_HANDLER_COUNT: <span class="s2">"20"</span>,
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: <span class="s2">"60000"</span>,
					NAME_NODE_HTTP_PORT: <span class="s2">"9002"</span>,
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: <span class="s2">"0.95"</span>,
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: <span class="s2">"4"</span>,
					NAME_NODE_RPC_PORT: <span class="s2">"9001"</span>,
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: <span class="s2">"0.9"</span>,
					PERMISSIONS_ENABLED: <span class="s2">"false"</span>,
					SERVICE_ZK_ROOT: <span class="s2">"dcos-service-hdfs"</span>,
					TASK_USER: <span class="s2">"root"</span>
				<span class="o">}</span>
			<span class="o">}</span>,
			health - check - spec: null,
			readiness - check - spec: null,
			config - files: <span class="o">[{</span>
				name: <span class="s2">"core-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}</span>, <span class="o">{</span>
				name: <span class="s2">"hdfs-site"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml"</span>,
				template - content: <span class="s2">"&lt;?xml version="</span>
				1.0 <span class="s2">" encoding="</span>
				UTF - 8 <span class="s2">" standalone="</span>
				no <span class="s2">"?&gt; &lt;?xml-stylesheet type="</span>
				text / xsl <span class="s2">" href="</span>
				configuration.xsl <span class="s2">"?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ RULE:[1:</span><span class="nv">$1</span><span class="s2">@</span><span class="nv">$0</span><span class="s2">](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/*@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{SECURITY_KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{SECURITY_KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{SECURITY_KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "</span>
			<span class="o">}</span>, <span class="o">{</span>
				name: <span class="s2">"hadoop-metrics2"</span>,
				relative - path: <span class="s2">"hadoop-2.6.0-cdh5.9.1/etc/hadoop/hadoop-metrics2.properties"</span>,
				template - content: <span class="s2">"# Autogenerated by the Mesos Framework, DO NOT EDIT *.sink.statsd.class=org.apache.hadoop.metrics2.sink.StatsDSink datanode.sink.statsd.period=10 datanode.sink.statsd.server.host={{STATSD_UDP_HOST}} datanode.sink.statsd.server.port={{STATSD_UDP_PORT}} datanode.sink.statsd.skip.hostname=false"</span>
			<span class="o">}]</span>
		<span class="o">}]</span>,
		placement - rule: <span class="o">{</span>
			@type: <span class="s2">"TaskTypeRule"</span>,
			<span class="nb">type</span>: <span class="s2">"data"</span>,
			converter: <span class="o">{</span>
				@type: <span class="s2">"TaskTypeLabelConverter"</span>
			<span class="o">}</span>,
			behavior: <span class="s2">"AVOID"</span>
		<span class="o">}</span>
	<span class="o">}]</span>,
	replacement - failure - policy: <span class="o">{</span>
		permanentFailureTimoutMins: null,
		minReplaceDelayMins: 0
	<span class="o">}</span>
<span class="o">}</span>
</code></pre>
</div>

<h2 id="list-configs">List Configs</h2>

<p>You can list all configuration IDs by sending a GET request to <code class="highlighter-rouge">/v1/configurations</code>.</p>

<p>CLI Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>dcos beta-hdfs config --name<span class="o">=</span>hdfs list
</code></pre>
</div>

<p>HTTP Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/configurations
<span class="o">[</span>
    <span class="s2">"9a8d4308-ab9d-4121-b460-696ec3368ad6"</span>
<span class="o">]</span>
</code></pre>
</div>

<h2 id="view-specified-config">View Specified Config</h2>

<p>You can view a specific configuration by sending a GET request to <code class="highlighter-rouge">/v1/configurations/&lt;config-id&gt;</code>.</p>

<p>CLI Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>dcos beta-hdfs config --name<span class="o">=</span>hdfs show 9a8d4308-ab9d-4121-b460-696ec3368ad6
</code></pre>
</div>

<p>HTTP Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/configurations/9a8d4308-ab9d-4121-b460-696ec3368ad6
<span class="o">{</span>
    ... same format as target config above ...
<span class="o">}</span>
</code></pre>
</div>

<h1 id="service-status-info">Service Status Info</h1>
<p>Send a GET request to the <code class="highlighter-rouge">/v1/state/properties/suppressed</code> endpoint to learn if HDFS is in a <code class="highlighter-rouge">suppressed</code> state and not receiving offers. If a service does not need offers, Mesos can suppress it so that other services are not starved for resources.
You can use this request to troubleshoot: if you think HDFS should be receiving resource offers, but is not, you can use this API call to see if HDFS is suppressed.</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>curl -H <span class="s2">"Authorization: token=</span><span class="nv">$auth_token</span><span class="s2">"</span> <span class="s2">"&lt;dcos_url&gt;/service/hdfs/v1/state/properties/suppressed"</span>
</code></pre>
</div>

</div>
</div>
</body>

</html>
